diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py
index 113b086bc..3ba0ab0fd 100644
--- a/pylint/checkers/similar.py
+++ b/pylint/checkers/similar.py
@@ -542,14 +542,6 @@ class Similar:
             for lineset2 in self.linesets[idx + 1 :]:
                 yield from self._find_common(lineset, lineset2)
 
-    def get_map_data(self):
-        """Returns the data we can use for a map/reduce process.
-
-        In this case we are returning this instance's Linesets, that is all file
-        information that will later be used for vectorisation.
-        """
-        return self.linesets
-
     def combine_mapreduce_data(self, linesets_collection):
         """Reduces and recombines data into a format that we can report on.
 
@@ -574,19 +566,24 @@ def stripped_lines(
     :param ignore_signatures: if true, any line that is part of a function signature is removed from the result
     :return: the collection of line/line number/line type tuples
     """
+    tree = None
+    signature_lines = set()
+    line_begins_import = {}
+    current_line_is_import = False
     if ignore_imports or ignore_signatures:
         tree = astroid.parse("".join(lines))
     if ignore_imports:
-        node_is_import_by_lineno = (
-            (node.lineno, isinstance(node, (nodes.Import, nodes.ImportFrom)))
-            for node in tree.body
-        )
-        line_begins_import = {
-            lineno: all(is_import for _, is_import in node_is_import_group)
-            for lineno, node_is_import_group in groupby(
-                node_is_import_by_lineno, key=lambda x: x[0]
+        if tree is not None:
+            node_is_import_by_lineno = (
+                (node.lineno, isinstance(node, (nodes.Import, nodes.ImportFrom)))
+                for node in tree.body
             )
-        }
+            line_begins_import = {
+                lineno: all(is_import for _, is_import in node_is_import_group)
+                for lineno, node_is_import_group in groupby(
+                    node_is_import_by_lineno, key=lambda x: x[0]
+                )
+            }
         current_line_is_import = False
     if ignore_signatures:
 
@@ -607,18 +604,19 @@ def stripped_lines(
 
             return functions
 
-        functions = _get_functions([], tree)
-        signature_lines = set(
-            chain(
-                *(
-                    range(
-                        func.lineno,
-                        func.body[0].lineno if func.body else func.tolineno + 1,
+        if tree is not None:
+            functions = _get_functions([], tree)
+            signature_lines = set(
+                chain(
+                    *(
+                        range(
+                            func.lineno,
+                            func.body[0].lineno if func.body else func.tolineno + 1,
+                        )
+                        for func in functions
                     )
-                    for func in functions
                 )
             )
-        )
 
     strippedlines = []
     docstring = None
@@ -821,7 +819,8 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):
     def open(self):
         """Init the checkers: reset linesets and statistics information."""
         self.linesets = []
-        self.linter.stats.reset_duplicated_lines()
+        if self.linter is not None:
+            self.linter.stats.reset_duplicated_lines()
 
     def process_module(self, node: nodes.Module) -> None:
         """Process a module.
@@ -830,7 +829,7 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):
 
         stream must implement the readlines method
         """
-        if self.linter.current_name is None:
+        if self.linter is not None and self.linter.current_name is None:
             warnings.warn(
                 (
                     "In pylint 3.0 the current_name attribute of the linter object should be a string. "
@@ -839,32 +838,52 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):
                 DeprecationWarning,
             )
         with node.stream() as stream:
+            # Check if this module should be skipped for the duplicate-code check
+            if not self.should_analyze_file(node.file):
+                return
             self.append_stream(self.linter.current_name, stream, node.file_encoding)  # type: ignore[arg-type]
 
+    def should_analyze_file(self, file_path: str) -> bool:
+        """Check if the file should be analyzed for duplicate code.
+
+        This checks for a disable comment for the duplicate-code check in the file.
+
+        :param file_path: The path to the file to check
+        :returns: True if the file should be analyzed, False otherwise
+        """
+        with open(file_path, 'r', encoding='utf-8') as file:
+            for line in file:
+                if 'pylint: disable=duplicate-code' in line:
+                    return False
+        return True
+
+    def get_map_data(self):
+        map_data = []
+        for lineset in self.linesets:
+            map_data.extend(lineset.stripped_lines)
+        return map_data
+
     def close(self):
         """Compute and display similarities on closing (i.e. end of parsing)."""
         total = sum(len(lineset) for lineset in self.linesets)
         duplicated = 0
-        stats = self.linter.stats
-        for num, couples in self._compute_sims():
-            msg = []
-            lineset = start_line = end_line = None
-            for lineset, start_line, end_line in couples:
-                msg.append(f"=={lineset.name}:[{start_line}:{end_line}]")
-            msg.sort()
-
-            if lineset:
-                for line in lineset.real_lines[start_line:end_line]:
-                    msg.append(line.rstrip())
-
-            self.add_message("R0801", args=(len(couples), "\n".join(msg)))
-            duplicated += num * (len(couples) - 1)
-        stats.nb_duplicated_lines += int(duplicated)
-        stats.percent_duplicated_lines += float(total and duplicated * 100.0 / total)
-
-    def get_map_data(self):
-        """Passthru override."""
-        return Similar.get_map_data(self)
+        if self.linter is not None:
+            stats = self.linter.stats
+            for num, couples in self._compute_sims():
+                msg = []
+                lineset = start_line = end_line = None
+                for lineset, start_line, end_line in couples:
+                    msg.append(f"=={lineset.name}:[{start_line}:{end_line}]")
+                msg.sort()
+
+                if lineset:
+                    for line in lineset.real_lines[start_line:end_line]:
+                        msg.append(line.rstrip())
+
+                self.add_message("R0801", args=(len(couples), "\n".join(msg)))
+                duplicated += num * (len(couples) - 1)
+            stats.nb_duplicated_lines += int(duplicated)
+            stats.percent_duplicated_lines += float(total and duplicated * 100.0 / total)
 
     def reduce_map_data(self, linter, data):
         """Reduces and recombines data into a format that we can report on.
@@ -903,14 +922,14 @@ def Run(argv=None):
         argv = sys.argv[1:]
 
     s_opts = "hdi"
-    l_opts = (
+    l_opts = [
         "help",
         "duplicates=",
         "ignore-comments",
         "ignore-imports",
         "ignore-docstrings",
         "ignore-signatures",
-    )
+    ]
     min_lines = DEFAULT_MIN_SIMILARITY_LINE
     ignore_comments = False
     ignore_docstrings = False
